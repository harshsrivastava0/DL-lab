CIFAR 10 EXP3.3

HERE I USED A VERY SIMPLE CNN ARCHITECTURE WITHOUT BACTH NORMALISATION AND DROOPUT 

ACTIVATION FUNCTION : RELU BUT IT IS ONLY USED IN THE FC LAYER

INITIALISATION : DEFAULT IN PYTORCH

OPTIMISER :  ADAM

LEARNING RATE : 0.001

EPOCHS = 10

TRAINING LOSS = 0.7247 

VALIDATION LOSS = 0.6696 

VALIDATION ACCURACY = 77.28%
